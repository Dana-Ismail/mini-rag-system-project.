{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Homework: Build and Test a Mini RAG System from Scratch üß†\n",
        "\n",
        "> **üéØ Today's Goal**: Combine the knowledge from the first three lessons (Embeddings, Retrieval, Generation) to build a functional Retrieval-Augmented Generation (RAG) system from scratch. Then, test it with a self-assessment!"
      ],
      "metadata": {
        "id": "Fg7IRyVjzb74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCUjET-gzbee",
        "outputId": "a19f9ff1-bb0c-4b91-fc40-7dacbceee310"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Part 1: The Retriever - Finding the Right Knowledge\n",
        "\n",
        "First, we'll set up our Retriever. Its job is to take a question and find the most relevant piece of text from our knowledge base.\n",
        "\n",
        "1.  **Load the Embedding Model** (`all-MiniLM-L6-v2`)\n",
        "2.  **Create our Knowledge Base**\n",
        "3.  **Encode Everything into Embeddings**\n",
        "4.  **Calculate Similarity** to find the best match"
      ],
      "metadata": {
        "id": "99P0U4tJzjq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "\n",
        "# 1. Load our embedding model\n",
        "retriever_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# 2. Create a simple knowledge base\n",
        "knowledge_base = [\n",
        "    \"The capital of France is Paris, a city famous for the Eiffel Tower and the Louvre museum.\",\n",
        "    \"The Amazon rainforest is the world's largest tropical rainforest, known for its incredible biodiversity.\",\n",
        "    \"Mount Everest is the highest mountain on Earth, located in the Himalayas.\",\n",
        "    \"The Great Wall of China is a series of fortifications stretching over 13,000 miles.\",\n",
        "    \"Photosynthesis is the process used by plants to convert light energy into chemical energy.\"\n",
        "]\n",
        "\n",
        "# 3. Encode our knowledge base into embeddings\n",
        "knowledge_embeddings = retriever_model.encode(knowledge_base, convert_to_tensor=True)\n",
        "\n",
        "print(f\"‚úÖ Retriever model loaded and knowledge base encoded with {len(knowledge_base)} documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "569e53ee01944da792ac8afbe95a65db",
            "242b86463a62416199104544b6954e0e",
            "86374787ed904d328a5641cd11e8d47b",
            "9d02382831b3419c96e96360a3514ab2",
            "8a5028c295c64f9fb3b5bb80e2a98ce9",
            "6ec21189665347fe9fed7b73fafab5a3",
            "af402e5475d049af978ef3c14c9de935",
            "b681b74790514bf4969a0ccf20138a4c",
            "3989692821464658a84a7a0611f91762",
            "24b26bbad33d4670b61ac3db93164d79",
            "5f0c54b4ddbd44969b64dcd5e9721cc8",
            "2d588b111eb440a49c359934b66a8a8c",
            "353a516d73cf48b895bfd8d0af78d787",
            "12b10b15a78e48f48f8e8f3631d94d43",
            "cef4bd334f804ee88e32f4beacf5bd95",
            "52782dee77574305aceb7ad593c5f47b",
            "65df9b1ce114438cb365769db3eb48d5",
            "2d1ff5be9fe646dbb4d7b883c25941a3",
            "0388042c6c254662813fdbde486541ca",
            "8d7fdcc3672245ac97f1aa756b136229",
            "a370cf691c7440028fd9295bd314c613",
            "e4dc4092493f40b8a8dc5b9eae86e417",
            "1e0c939ed52d4490b429ff766a77ccec",
            "bd047bbe5dea4d5c8bb3be01179b3d50",
            "cf35b5ab46e94e7e91023be4839d0e9f",
            "cae98b4b7e034a36a49c8e59a05b1e53",
            "9ced99a6756247b49b39a25604f93c2c",
            "7ce97531996745589fad08b968ae0c16",
            "aa653accd1084871b97f48259b9f8471",
            "7954cc384d9a46a28a273f892f17cfab",
            "7fd572c1755a45d6adde2dc329d0e6b7",
            "1ec67d144cb1425fbe3b5bbc5015d64f",
            "5a331c29c2a149b48df6f501fea229da",
            "1dba15ef9cb8442c9d8dc606fcd609e4",
            "679b9b1ddb5e4b23bbda472eaacf755c",
            "bfe73cf68ecb43688188c6c68e4f95d5",
            "21d14f846916487d8014bf96e417f289",
            "dd9c4575f1094daf99d77a6a62349bea",
            "cbead44c60eb42f8a25fd7b19cf4a39c",
            "1657f80638e649f2a1d18dfca129a203",
            "36d14149b3184d0d968f275164bf04c9",
            "8cef9cb4212d4f7cb2271384740edee0",
            "5ac6df70f5134758b2492837b5cd1be3",
            "8fb6e39a9e1c41278065ac682b00c698",
            "c23686ceef9d44c1b52f4544188901f4",
            "b844a7f0753c4649ab6b7af9d9e0fdc3",
            "69991728450a405b85a54c11d473b620",
            "4ba04c2a71154775ac9fb6831e712dba",
            "192d18eb64924b52bfb9f612dbecba4e",
            "7fa9ca1a4fe042b4b54335dc0afc70bb",
            "8b80069add9343f79d40c5949734418a",
            "fbc227e926814703935a2def27e8de81",
            "58a098a229d44148ad2da81aa75f1ab7",
            "e519697cd4524ec49d7f487a7293b384",
            "984bbf36fde64d45a0e31eb8bcde99f3",
            "f719ef238eb445b4b0f9c0cbc99ae49a",
            "ca5f3c46b2aa424b801eb6741e157d37",
            "8df11489a7944bf385efd8eed0ecf7c6",
            "c8e3aea534114034a1946537a3f6f310",
            "f0476c84d51245638e2fb673b1373087",
            "60a83db280334b00a8bd15dd16178e23",
            "72daee609e3644f08ca2face76ef042c",
            "9233deac084e46dab0619a0046c84aa5",
            "a60919253cf241499b1ff5700bab5713",
            "54a708307bbb4d8793972f474ef96407",
            "3d01ac2461e947dd8175ac8354bb5aaf",
            "c430720a82b14420a3001a95d5ff8cec",
            "13e3055e77eb4197a0b6923621bc12a3",
            "9ddf7736c50d4dbfb85deae8ecb5dee5",
            "24da95850dc64e88b7eb818420d767ed",
            "278cf91e85a64f1c853031906ebe62ea",
            "795092ff89de4e36b122a7ab2d4ead6c",
            "4f95de878e904b05a28b97306fb3093f",
            "c3fe6fb7e86b4e918f58acc520a73790",
            "532d8ebe82474a369d08e5d348feb9e5",
            "868ebe9d33594d689bde05ec3484aeb2",
            "ae80685bd45b4f41b4a3e72c4ad39276",
            "4a120b6989e44195a2c0d530592bc2c9",
            "04a2a9c2b4254cc3a740ec24a46c16db",
            "14accc0bea2a4cdba56168a79b86c478",
            "5ee30b40f15b463898f2a68010402dec",
            "e3f1ff4eb931453aa688468bd4d98ca4",
            "5b342bcf6b6a4334a3ef42508398cf5a",
            "112dc59185db47b8816246b35053b92e",
            "40866bc399d14eb7bf1f3c443e6817ab",
            "f155ddf79e9c44ada1fa1ea68d70ed52",
            "b1615865ea354d5d987b46445b3f9712",
            "2312a0a5debd4c99bbd48cfed413c2d1",
            "91eecf3841a64f09a92ffff47fb09db2",
            "0df66281ae2d42ae8553423069a725f7",
            "2534e3c35f9745df9289b0c70927b288",
            "673b1b1863e74c718820d7b8ffc93525",
            "cee478dfc2dc480baafeb0ecbf6524cf",
            "bf1a4fa67ece4ccf8e28519b59b6e9c7",
            "d85605d1b7fe45e5b093a866ab9842d1",
            "1a3ec66a6d0f4d92adefcbf04db8c37f",
            "010ad85d3c544fa8b0b4ec67555cada2",
            "9b3e6e4c50b04db59b42fcaa23e3d733",
            "8dd04c84c41c4816b5a8555bc62c851e",
            "b32a752529284cb98a7ddbddbb83db04",
            "936b2dce9c874c82b22610392eefa388",
            "c3e925e972f94a9aa248e8bd5ae0ce72",
            "2191095b27c3438eb16fde5ecd0bb7d2",
            "5242af6fb9844e4d9df98afc4d85f327",
            "4df0028faec640d4827e78e523ea9649",
            "d4fcff5e9ee44845a0657cf086cf4cee",
            "9770e30fde8540ddaa7b6f75a3f38ed3",
            "e49f6c133c8d4bb8939588a151e7237a",
            "bfddd822739f430ca6564c75bff67eec",
            "24e653cea9784dec9938973a37bcd060",
            "b5d53daca5b64cf8ab3dde77bb9324a0",
            "09172f3ee39243cea880cc6cd7db0556",
            "8c9853f4172f4a859dace985d175bdc0",
            "a47a4b3f3de0423994c77f555b15c5d6",
            "e8df657816ac449aae3660d4681fe179",
            "71cab27ae17c49729ad4cad9edbddf52",
            "7599dc0c22984648b525c142c2d7bb82",
            "62c9aa81e09446519fac976a161ac55b",
            "63a28363384a4d5db0b9e2aee8956215",
            "c8782ced2bb748889ace7f552f750048",
            "e1a900ac87e544f7ae606b616e12a6c1"
          ]
        },
        "id": "CJHpc394zkYw",
        "outputId": "51aafa4f-dc73-4451-c9ea-e89f9c857620"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "569e53ee01944da792ac8afbe95a65db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d588b111eb440a49c359934b66a8a8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e0c939ed52d4490b429ff766a77ccec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dba15ef9cb8442c9d8dc606fcd609e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c23686ceef9d44c1b52f4544188901f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f719ef238eb445b4b0f9c0cbc99ae49a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c430720a82b14420a3001a95d5ff8cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a120b6989e44195a2c0d530592bc2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91eecf3841a64f09a92ffff47fb09db2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b32a752529284cb98a7ddbddbb83db04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5d53daca5b64cf8ab3dde77bb9324a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Retriever model loaded and knowledge base encoded with 5 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úçÔ∏è Part 2: The Generator - Extracting the Answer\n",
        "\n",
        "Now we set up our Generator. This model will take the question and the context found by the retriever and extract the exact answer from it."
      ],
      "metadata": {
        "id": "Plr7LaDsznpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our question-answering (generator) model\n",
        "generator = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
        "\n",
        "print(\"‚úÖ Generator (QA) model loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "79422ac1ffea412686a039ddc5415b53",
            "99c8b3aec94b4b36a59561b926bf8a51",
            "038c2b1fc0b34079a28a633032c621da",
            "bbf71f7de07e4d4b9f05e5ed0ab5cf97",
            "6b218c84877041c9b97159a41b7d7471",
            "fba4c36cd33a41ce94fc4ac60080378b",
            "b5d24516015b446cba916557059e1ef2",
            "cd6e337c1b3240ec953e8eb402c3a421",
            "82c98d5c5cc748e2abe79a02cca11970",
            "a7a238fcacd54e1b8da224ab8eab8b30",
            "284fcb418fac43cb9eb4106211e4ed4c",
            "e6c26c8d2a7444049ab12e7f6633ae45",
            "785cb34d96694088a25a4db7f1d85f27",
            "c37ab82ffaf248edbeada337f9d60847",
            "50b2c505397f4198b1f5467ba504a3fe",
            "835495c386fe4cc1aebdba1f01ee33fd",
            "cd40f19e71b74280aa2edc8ff8833b0d",
            "b4bd13a57fa44ffcaa71b90525283094",
            "7e20fb75239c415e9989f2607cbc0e8d",
            "ec0f7885ca5748239f0d321a367db434",
            "192c06d509d940e88c938f5746005b6a",
            "793209680a874d989248efa443d28c71",
            "c43a6afde1f54768ae1689be76020a8e",
            "7a105cd4f47a4fe0addbb03da4b87719",
            "b60e8eb86529432a9397d94ab1351a02",
            "1e3bf8f4f0a1478cb1a9914820089a47",
            "79154d57801a41a79713a09b7e456e11",
            "c6ce6d8ab43e499d9f99275262c880be",
            "2e215de6da354379be29f0908291402b",
            "db6184cfb56d4786b9fb7506b8d4ad53",
            "6b8c8d22281a485a9629a665fa75bf06",
            "8270c626d997439ea9ecea09d78a91f0",
            "f69a16bd58c6491eb1b43e6d6be48715",
            "7fe8250d58a641c3935268d11f18a61e",
            "432b7503a947470e9e2cedd4ce3f9c31",
            "e7e48184fdab4b939626d028f923819f",
            "59edbce2b3384bf2a81ed4e52a73262a",
            "f158582f05504bc1b10006df0af2eedb",
            "388f91447d1e4ce1a1940c88ca0e9bda",
            "a6a2f0ef338446d29c16b217570f7066",
            "3ba6ab0eb76347ddaefc8ea1b9d0685e",
            "d80f492b8ac14e76a347546ac6a247d8",
            "7da575de1fb94ecca194ee88de41d6bd",
            "4a9a5a7eff974ffe8dff730186ad8c57",
            "e6bb9782c21d40c0825015744d53fcc0",
            "e88308a862f143559bfc73a0286e42b6",
            "79cc5e59a7864c5eb9bc772bc4489205",
            "a98fbb1ddf4a4f9badf292813d474033",
            "9bc2fd0ed70948418f4393a4d4e0f594",
            "19aaaf94bfde4cd190ce15741731971a",
            "7b3eb1887ac84d64895c859dc5c15df0",
            "1bfb93cc568d4c5591bbf9d7f4fed702",
            "2ac07f93f9594c9fa7e01a8bad295025",
            "7d95dba1d6f3408090288ea5b8881521",
            "f9f580b78d0a49e491d890ad67f5068b"
          ]
        },
        "id": "sCHCTi1xzpto",
        "outputId": "5fc9a55e-78d4-48c6-c98e-547b2303a3ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79422ac1ffea412686a039ddc5415b53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6c26c8d2a7444049ab12e7f6633ae45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c43a6afde1f54768ae1689be76020a8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fe8250d58a641c3935268d11f18a61e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6bb9782c21d40c0825015744d53fcc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Generator (QA) model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Part 3: Testing our RAG System\n",
        "\n",
        "Time to put it all together! The function below will simulate a full RAG pipeline and grade itself against a predefined set of questions and answers.\n",
        "\n",
        "It will test two key things:\n",
        "1.  **Retrieval Accuracy**: Did we find the right document?\n",
        "2.  **Generation Accuracy**: Did we extract the correct answer from that document?"
      ],
      "metadata": {
        "id": "kJMFmEjgzsIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_rag_assessment():\n",
        "    \"\"\"Runs a self-assessment of the RAG pipeline with multiple questions.\"\"\"\n",
        "\n",
        "    # Define our questions, expected context keywords, and expected answers\n",
        "    test_questions = [\n",
        "        {\n",
        "            \"question\": \"What is the highest mountain?\",\n",
        "            \"expected_keyword\": \"Everest\",\n",
        "            \"expected_answer\": \"Mount Everest\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Which city is home to the Louvre museum?\",\n",
        "            \"expected_keyword\": \"France\",\n",
        "            \"expected_answer\": \"Paris\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What process do plants use for energy?\",\n",
        "            \"expected_keyword\": \"Photosynthesis\",\n",
        "            \"expected_answer\": \"Photosynthesis\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    score = 0\n",
        "    total = len(test_questions) * 2 # 2 points per question (1 for retrieval, 1 for generation)\n",
        "\n",
        "    print(\"--- üöÄ Starting RAG System Assessment ---\\n\")\n",
        "\n",
        "    for i, test in enumerate(test_questions):\n",
        "        question = test[\"question\"]\n",
        "        print(f\"\\n--- Question {i+1}: '{question}' ---\")\n",
        "\n",
        "        # --- 1. Retrieval Step ---\n",
        "        question_embedding = retriever_model.encode(question, convert_to_tensor=True)\n",
        "        cos_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings)[0]\n",
        "        top_result_index = torch.argmax(cos_scores)\n",
        "        retrieved_context = knowledge_base[top_result_index]\n",
        "\n",
        "        print(f\"üîé  Retrieved Context: '{retrieved_context}'\")\n",
        "\n",
        "        # Check if the retrieval was correct\n",
        "        if test[\"expected_keyword\"] in retrieved_context:\n",
        "            print(\"‚úÖ  Retrieval Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå  Retrieval Failed. Expected context with keyword: '{test['expected_keyword']}'\")\n",
        "\n",
        "        # --- 2. Generation Step ---\n",
        "        qa_result = generator(question=question, context=retrieved_context)\n",
        "        generated_answer = qa_result['answer']\n",
        "\n",
        "        print(f\"‚úçÔ∏è  Generated Answer: '{generated_answer}'\")\n",
        "\n",
        "        # Check if the generation was correct\n",
        "        if test[\"expected_answer\"].lower() in generated_answer.lower():\n",
        "            print(\"‚úÖ  Generation Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå  Generation Failed. Expected answer: '{test['expected_answer']}'\")\n",
        "\n",
        "    # --- Final Score ---\n",
        "    print(f\"\\n--- üèÅ Assessment Complete ---\")\n",
        "    print(f\"üéØ Final Score: {score} / {total}\")\n",
        "    if score == total:\n",
        "        print(\"üéâüéâüéâ Perfect! Your RAG system is working as expected!\")\n",
        "    elif score >= total / 2:\n",
        "        print(\"üëç Good job! The system is mostly correct.\")\n",
        "    else:\n",
        "        print(\"üîß The system ran into some issues. Review the steps and check the logic.\")\n",
        "\n",
        "# Run the assessment!\n",
        "run_rag_assessment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvP6XETQztxR",
        "outputId": "f2bc1410-9c27-4c74-d46f-4423e08baed8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üöÄ Starting RAG System Assessment ---\n",
            "\n",
            "\n",
            "--- Question 1: 'What is the highest mountain?' ---\n",
            "üîé  Retrieved Context: 'Mount Everest is the highest mountain on Earth, located in the Himalayas.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'Mount Everest'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 2: 'Which city is home to the Louvre museum?' ---\n",
            "üîé  Retrieved Context: 'The capital of France is Paris, a city famous for the Eiffel Tower and the Louvre museum.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'Paris'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 3: 'What process do plants use for energy?' ---\n",
            "üîé  Retrieved Context: 'Photosynthesis is the process used by plants to convert light energy into chemical energy.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'Photosynthesis'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- üèÅ Assessment Complete ---\n",
            "üéØ Final Score: 6 / 6\n",
            "üéâüéâüéâ Perfect! Your RAG system is working as expected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  STUDENT TASKS üßë‚Äçüíª\n",
        "\n",
        "Now it's your turn to be the AI engineer. Your tasks are to run, analyze, and extend the RAG system you've just built."
      ],
      "metadata": {
        "id": "bmsraUmd0ruq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Execute and Understand\n",
        "\n",
        "Your first task is to simply run all the cells above and carefully read the output of the final self-assessment.\n",
        "\n",
        "* **Observe the Score:** Did the system get a perfect score (6/6)?\n",
        "* **Analyze Each Step:** For each question, look at the \"Retrieved Context\" and the \"Generated Answer.\"\n",
        "    * Did the retriever find the correct piece of knowledge?\n",
        "    * Did the generator extract the right answer from that context?"
      ],
      "metadata": {
        "id": "RT5z7ZoE0trr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 (Challenge): Add a New Question\n",
        "\n",
        "Your second task is to test the system with a new question about the **existing knowledge**.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Copy the code from the cell below. It's the same assessment function as before, but with a new test question added.\n",
        "2.  Run the cell and see if the system can answer correctly. The score should now be out of 8."
      ],
      "metadata": {
        "id": "25iQeOoo6jTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Add a new question to the assessment function\n",
        "\n",
        "def run_rag_assessment_task_2():\n",
        "    test_questions = [\n",
        "        {\n",
        "            \"question\": \"What is the highest mountain?\",\n",
        "            \"expected_keyword\": \"Everest\",\n",
        "            \"expected_answer\": \"Mount Everest\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Which city is home to the Louvre museum?\",\n",
        "            \"expected_keyword\": \"France\",\n",
        "            \"expected_answer\": \"Paris\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What process do plants use for energy?\",\n",
        "            \"expected_keyword\": \"Photosynthesis\",\n",
        "            \"expected_answer\": \"Photosynthesis\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How many miles does the Great Wall of China stretch?\",\n",
        "            \"expected_keyword\": \"13,000\",\n",
        "            \"expected_answer\": \"13,000\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    score = 0\n",
        "    total = len(test_questions) * 2\n",
        "\n",
        "    print(\"--- üöÄ Starting RAG System Assessment (Task 2) ---\\n\")\n",
        "\n",
        "    for i, test in enumerate(test_questions):\n",
        "        question = test[\"question\"]\n",
        "        print(f\"\\n--- Question {i+1}: '{question}' ---\")\n",
        "        question_embedding = retriever_model.encode(question, convert_to_tensor=True)\n",
        "        cos_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings)[0]\n",
        "        top_result_index = torch.argmax(cos_scores)\n",
        "        retrieved_context = knowledge_base[top_result_index]\n",
        "        print(f\"üîé  Retrieved Context: '{retrieved_context}'\")\n",
        "        if test[\"expected_keyword\"] in retrieved_context:\n",
        "            print(\"‚úÖ  Retrieval Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå  Retrieval Failed. Expected context with keyword: '{test['expected_keyword']}'\")\n",
        "        qa_result = generator(question=question, context=retrieved_context)\n",
        "        generated_answer = qa_result['answer']\n",
        "        print(f\"‚úçÔ∏è  Generated Answer: '{generated_answer}'\")\n",
        "        if test[\"expected_answer\"].lower() in generated_answer.lower():\n",
        "            print(\"‚úÖ  Generation Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå  Generation Failed. Expected answer: '{test['expected_answer']}'\")\n",
        "\n",
        "    print(f\"\\n--- üèÅ Assessment Complete ---\")\n",
        "    print(f\"üéØ Final Score: {score} / {total}\")\n",
        "    if score == total:\n",
        "        print(\"üéâüéâüéâ Perfect! Your RAG system handled the new question!\")\n",
        "\n",
        "# Run the updated assessment\n",
        "run_rag_assessment_task_2()"
      ],
      "metadata": {
        "id": "6TKb4uBO6pEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b6dc78-acd7-42fc-e700-1fc870865933"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üöÄ Starting RAG System Assessment (Task 2) ---\n",
            "\n",
            "\n",
            "--- Question 1: 'What is the highest mountain?' ---\n",
            "üîé  Retrieved Context: 'Mount Everest is the highest mountain on Earth, located in the Himalayas.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'Mount Everest'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 2: 'Which city is home to the Louvre museum?' ---\n",
            "üîé  Retrieved Context: 'The capital of France is Paris, a city famous for the Eiffel Tower and the Louvre museum.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'Paris'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 3: 'What process do plants use for energy?' ---\n",
            "üîé  Retrieved Context: 'Photosynthesis is the process used by plants to convert light energy into chemical energy.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'Photosynthesis'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 4: 'How many miles does the Great Wall of China stretch?' ---\n",
            "üîé  Retrieved Context: 'The Great Wall of China is a series of fortifications stretching over 13,000 miles.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: '13,000'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- üèÅ Assessment Complete ---\n",
            "üéØ Final Score: 8 / 8\n",
            "üéâüéâüéâ Perfect! Your RAG system handled the new question!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3 (Advanced Challenge): Add New Knowledge & Test It\n",
        "\n",
        "Your final and most important task is to **expand the RAG system's knowledge base** and then test it.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Add a new fact** to the `knowledge_base` in the code cell below.\n",
        "2.  **You must re-run this cell** to update the `knowledge_embeddings`! The system won't know about the new fact until you do.\n",
        "3.  Finally, run the last code cell, which has a new test question about the knowledge you just added."
      ],
      "metadata": {
        "id": "JNHQuccw7Duu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3, Step 1: Add a new sentence to the knowledge base\n",
        "\n",
        "knowledge_base_task_3 = [\n",
        "    \"MBTI (Myers-Briggs Type Indicator) is a personality typing system that categorizes people into 16 personality types based on preferences in how they perceive the world and make decisions.\",\n",
        "    \"Machine learning is divided into three main types: supervised learning, unsupervised learning, and reinforcement learning.\",\n",
        "    \"Sedimentary rocks are formed from the accumulation and compaction of sediments over time, often in layers, and can contain fossils.\",\n",
        "    \"Spanish is the official language in many countries, including Spain, Mexico, Argentina, Colombia, Peru, Chile, Ecuador, Guatemala, Cuba, Bolivia, Dominican Republic, Honduras, Paraguay, El Salvador, Nicaragua, Costa Rica, Puerto Rico, Panama, Uruguay, and Venezuela.\"\n",
        "]\n",
        "\n",
        "# Re-encode the updated knowledge base\n",
        "knowledge_embeddings_task_3 = retriever_model.encode(knowledge_base_task_3, convert_to_tensor=True)\n",
        "\n",
        "print(f\"‚úÖ Knowledge base updated and re-encoded with {len(knowledge_base_task_3)} documents.\")"
      ],
      "metadata": {
        "id": "4ijwpN1W7VyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18a0953-e284-4026-cf06-ac3a78d1d1e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Knowledge base updated and re-encoded with 4 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_rag_assessment_task_3():\n",
        "    test_questions = [\n",
        "        {\n",
        "            \"question\": \"What are the main types of machine learning?\",\n",
        "            \"expected_keyword\": \"Machine learning\",\n",
        "            \"expected_answer\": \"supervised learning, unsupervised learning, reinforcement learning\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Which system categorizes people into 16 personality types?\",\n",
        "            \"expected_keyword\": \"MBTI\",\n",
        "            \"expected_answer\": \"MBTI\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How are sedimentary rocks formed?\",\n",
        "            \"expected_keyword\": \"sedimentary rocks\",\n",
        "            \"expected_answer\": \"from the accumulation and compaction of sediments\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"List the countries where Spanish is the official language. How many are there?\",\n",
        "            \"expected_keyword\": \"Spanish\",\n",
        "            \"expected_answer\": \"20\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    score = 0\n",
        "    total = len(test_questions) * 2\n",
        "\n",
        "    print(\"--- üöÄ Starting RAG System Assessment (Task 3) ---\\n\")\n",
        "\n",
        "    for i, test in enumerate(test_questions):\n",
        "        question = test[\"question\"]\n",
        "        print(f\"\\n--- Question {i+1}: '{question}' ---\")\n",
        "\n",
        "        # --- Retrieval Step ---\n",
        "        question_embedding = retriever_model.encode(question, convert_to_tensor=True)\n",
        "        cos_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings_task_3)[0]\n",
        "        top_result_index = torch.argmax(cos_scores)\n",
        "        retrieved_context = knowledge_base_task_3[top_result_index]\n",
        "        print(f\"üîé  Retrieved Context: '{retrieved_context}'\")\n",
        "\n",
        "        if test[\"expected_keyword\"] in retrieved_context:\n",
        "            print(\"‚úÖ  Retrieval Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå  Retrieval Failed. Expected context with keyword: '{test['expected_keyword']}'\")\n",
        "        qa_result = generator(question=question, context=retrieved_context)\n",
        "        generated_answer = qa_result['answer']\n",
        "        print(f\"‚úçÔ∏è  Generated Answer: '{generated_answer}'\")\n",
        "\n",
        "        if test[\"expected_answer\"].lower() in generated_answer.lower():\n",
        "            print(\"‚úÖ  Generation Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå  Generation Failed. Expected answer: '{test['expected_answer']}'\")\n",
        "\n",
        "    print(f\"\\n--- üèÅ Assessment Complete ---\")\n",
        "    print(f\"üéØ Final Score: {score} / {total}\")\n",
        "    if score == total:\n",
        "        print(\"üèÜüèÜüèÜ Success! You have successfully extended the knowledge of your RAG system!\")"
      ],
      "metadata": {
        "id": "-tgQJ13P7pCs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_rag_assessment_task_3()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mthMIjSiNQ6",
        "outputId": "0233d189-cbd0-496c-b24e-e4bd867299c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üöÄ Starting RAG System Assessment (Task 3) ---\n",
            "\n",
            "\n",
            "--- Question 1: 'What are the main types of machine learning?' ---\n",
            "üîé  Retrieved Context: 'Machine learning is divided into three main types: supervised learning, unsupervised learning, and reinforcement learning.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'supervised learning, unsupervised learning, and reinforcement learning'\n",
            "‚ùå  Generation Failed. Expected answer: 'supervised learning, unsupervised learning, reinforcement learning'\n",
            "\n",
            "--- Question 2: 'Which system categorizes people into 16 personality types?' ---\n",
            "üîé  Retrieved Context: 'MBTI (Myers-Briggs Type Indicator) is a personality typing system that categorizes people into 16 personality types based on preferences in how they perceive the world and make decisions.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'MBTI'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 3: 'How are sedimentary rocks formed?' ---\n",
            "üîé  Retrieved Context: 'Sedimentary rocks are formed from the accumulation and compaction of sediments over time, often in layers, and can contain fossils.'\n",
            "‚ùå  Retrieval Failed. Expected context with keyword: 'sedimentary rocks'\n",
            "‚úçÔ∏è  Generated Answer: 'from the accumulation and compaction of sediments over time'\n",
            "‚úÖ  Generation Correct!\n",
            "\n",
            "--- Question 4: 'List the countries where Spanish is the official language. How many are there?' ---\n",
            "üîé  Retrieved Context: 'Spanish is the official language in many countries, including Spain, Mexico, Argentina, Colombia, Peru, Chile, Ecuador, Guatemala, Cuba, Bolivia, Dominican Republic, Honduras, Paraguay, El Salvador, Nicaragua, Costa Rica, Puerto Rico, Panama, Uruguay, and Venezuela.'\n",
            "‚úÖ  Retrieval Correct!\n",
            "‚úçÔ∏è  Generated Answer: 'many countries'\n",
            "‚ùå  Generation Failed. Expected answer: '20'\n",
            "\n",
            "--- üèÅ Assessment Complete ---\n",
            "üéØ Final Score: 5 / 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ùó ‚ö†Ô∏è ‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è ‚ùó ‚ö†Ô∏è ‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó ‚ö†Ô∏è‚ùó\n",
        "### Note on Tricky Question\n",
        "\n",
        "The last question, \"List the countries where Spanish is the official language. How many are there?\", shows a limitation of this RAG system:\n",
        "\n",
        "- ‚úÖ Retrieval was correct ‚Äî the system found the relevant context.\n",
        "- ‚ùå Generation failed ‚Äî the system returned \"many countries\" instead of the exact number \"20\".\n",
        "\n",
        "**Reason:** The generator is designed to extract text from context, but it does not automatically count items in a list.  \n",
        "\n",
        "**Possible improvements:**\n",
        "- Add post-processing to count items in the retrieved list.\n",
        "- Use structured data in the knowledge base for precise numerical queries.\n",
        "- Combine RAG with simple computational logic for numeric answers.\n"
      ],
      "metadata": {
        "id": "ajaVcfTtzW8B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXksDB3pzfxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
